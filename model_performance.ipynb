{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(pred, y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    if len(pred) == len(y):\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == pred[i] and y[i] == 0:\n",
    "                TN += 1\n",
    "            elif y[i] == pred[i] and y[i] != 0:\n",
    "                TP += 1\n",
    "            elif y[i] != pred[i] and y[i] == 0:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    \n",
    "    return TP, TN, FP, FN, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "dnn = models.load_model(\"dnn\")\n",
    "lstm = models.load_model(\"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"bert_output.csv\", encoding=\"utf-8-sig\")\n",
    "def word2vec(ar, model):\n",
    "    para_avg_vec = []\n",
    "    # print(\"training finished\")\n",
    "    # 对每一段\n",
    "    for para in ar:\n",
    "        sum_vec = np.zeros(100)\n",
    "        # 对每一段中每一个词\n",
    "        for word in para:\n",
    "            try:\n",
    "                # 试着从模型中取得word vector\n",
    "                sum_vec += model.wv[word]\n",
    "            except(KeyError):\n",
    "                # 如果有未记录的特殊符号，就跳过\n",
    "                continue\n",
    "        # 对词向量求平均得到句子的向量表示\n",
    "        para_avg_vec.append(sum_vec / len(para))\n",
    "    return para_avg_vec\n",
    "\n",
    "word_2_vec_model = Word2Vec.load('w2v_model')\n",
    "vec = word2vec(np.array(df[\"Column6\"]), word_2_vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 3ms/step\n",
      "125/125 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.convert_to_tensor(vec)\n",
    "dnn_predict = dnn.predict(x)\n",
    "lstm_predict = lstm.predict(x)\n",
    "bert_predict = df[\"Column13\"]\n",
    "\n",
    "y = df[\"Column7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(pred, num=[0, 2], num_labels=3):\n",
    "    delta = num[1] - num[0]\n",
    "    d = delta / num_labels\n",
    "    for i in range(len(pred)):\n",
    "        c = 0\n",
    "        if pred[i] <= num[0] + d:\n",
    "            pred[i] = c\n",
    "        elif pred[i] <= num[0] + 2*d:\n",
    "            pred[i] = c + 1\n",
    "        else:\n",
    "            pred[i] = c + 2\n",
    "    return pred\n",
    "\n",
    "dnn_pred, lstm_pred = transform(dnn_predict), transform(lstm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_dnn, TN_dnn, FP_dnn, FN_dnn, accuracy_dnn, precision_dnn, recall_dnn = stat(dnn_pred, y)\n",
    "accuracy_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8926369241929634 0.7800316957210777\n"
     ]
    }
   ],
   "source": [
    "print(precision_dnn, recall_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6995 0.8398886181691612 0.7648177496038034\n"
     ]
    }
   ],
   "source": [
    "TP_lstm, TN_lstm, FP_lstm, FN_lstm, accuracy_lstm, precision_lstm, recall_lstm = stat(lstm_pred, y)\n",
    "print(accuracy_lstm, precision_lstm, recall_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49525 0.809368191721133 0.47099841521394614\n"
     ]
    }
   ],
   "source": [
    "TP_bert, TN_bert, FP_bert, FN_bert, accuracy_bert, precision_bert, recall_bert = stat(bert_predict, y)\n",
    "print(accuracy_bert, precision_bert, recall_bert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
